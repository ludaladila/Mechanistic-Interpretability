
# Mechanistic-Interpretability

Yiqing Liu

## Introduction

This project builds and trains a small neural network to solve the XOR task. The notebook examines the model’s internal behavior using several interpretability techniques.

## What This Notebook Does

* Trains a tiny MLP on XOR
* Visualizes weights and hidden activations
* Plots decision boundaries
* Runs input sweeps to observe activation changes
* Performs neuron ablation to test each neuron’s role
